# Fast Block Partitioning

ä½¿ç”¨æ©Ÿå™¨å­¸ç¿’åŠ é€Ÿå½±åƒ/è¦–è¨Šç·¨ç¢¼å™¨ä¸­çš„å€å¡Šåˆ†å‰²æ±ºç­–ï¼ˆBlock Partitioning Decisionï¼‰ã€‚

## å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆæ¨¡æ“¬è¦–è¨Šç·¨ç¢¼å™¨ä¸­çš„ **Quadtree Block Partitioning** æ±ºç­–æµç¨‹ï¼Œå±•ç¤ºå¦‚ä½•é€é ML æ¨¡å‹åŠ é€Ÿå‚³çµ±çš„ RDOï¼ˆRate-Distortion Optimizationï¼‰è¨ˆç®—ã€‚

### æ ¸å¿ƒæ¦‚å¿µ

| æ¨¡å‹ | èªªæ˜ | ç‰¹é» |
|------|------|------|
| **C Model** | å®Œæ•´ RDO è¨ˆç®— | ç²¾ç¢ºä½†è€—æ™‚ |
| **Binary Model** | ML å¿«é€Ÿé æ¸¬ | å¿«é€Ÿä½†å¯èƒ½ä¸æº– |
| **Hybrid Model** | æ ¹æ“š Confidence æ±ºå®šç­–ç•¥ | å¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºåº¦ |

### Hybrid ç­–ç•¥

```
if (ML_Confidence >= Threshold):
    æ¡ç”¨ ML é æ¸¬çµæœ (å¿«é€Ÿè·¯å¾‘)
else:
    å›é€€åˆ° RDO è¨ˆç®— (ä¿è­‰å“è³ª)
```

## å°ˆæ¡ˆæ¶æ§‹

```
Fast Block Partitioning/
â”œâ”€â”€ ground_truth.cpp       # Phase 1: Ground Truth è³‡æ–™ç”Ÿæˆ
â”œâ”€â”€ train_and_convert.py   # Phase 2: ML æ¨¡å‹è¨“ç·´ & C++ è½‰è­¯
â”œâ”€â”€ main_hybrid.cpp        # Phase 3: Benchmark & Pareto åˆ†æ
â”œâ”€â”€ ml_model_generated.h   # è‡ªå‹•ç”Ÿæˆçš„ ML æ¨¡å‹ C++ ç¨‹å¼ç¢¼
â”œâ”€â”€ block_data.csv         # è¨“ç·´è³‡æ–™é›†
â”œâ”€â”€ pareto_data.csv        # Pareto Frontier æ•¸æ“š
â””â”€â”€ README.md
```

## å¿«é€Ÿé–‹å§‹

### 1. Phase 1: ç”Ÿæˆ Ground Truth

```bash
g++ -o ground_truth ground_truth.cpp && ./ground_truth
```

ç”¢ç”Ÿ `block_data.csv`ï¼ˆè¨“ç·´è³‡æ–™ï¼‰

### 2. Phase 2: è¨“ç·´ ML æ¨¡å‹

```bash
pip install pandas scikit-learn
python train_and_convert.py
```

ç”¢ç”Ÿ `ml_model_generated.h`ï¼ˆC++ å¯ç”¨çš„ Decision Treeï¼‰

### 3. Phase 3: æ•ˆèƒ½æ¸¬è©¦

```bash
g++ -O2 -std=c++11 -o main_hybrid main_hybrid.cpp && ./main_hybrid
```

## RDO (Rate-Distortion Optimization) å¯¦ä½œ

æœ¬å°ˆæ¡ˆå¯¦ä½œçœŸæ­£çš„ RDO è¨ˆç®—ï¼Œè€Œéæ¨¡æ“¬å»¶é²ï¼š

```cpp
// RD Cost = Distortion + Î» Ã— Rate
struct RDOResult {
    double cost_no_split;   // ä¸åˆ‡åˆ†çš„ RD Cost
    double cost_split;      // åˆ‡åˆ†çš„ RD Cost  
    bool should_split;      // cost_split < cost_no_split?
};
```

- **Distortion**: ä½¿ç”¨ SSD (Sum of Squared Differences) è¨ˆç®—å¤±çœŸ
- **Rate**: ä½¿ç”¨ `log2(variance + 1)` ä¼°è¨ˆç·¨ç¢¼ä½å…ƒæ•¸
- **Lambda (Î»)**: Lagrangian multiplierï¼Œæ§åˆ¶ Rate-Distortion æ¬Šè¡¡

## å¯¦é©—çµæœ

### æ¸¬è©¦åœ–ç‰‡

![Test Image Analysis](dummy_image_analysis.png)

### ä¸åŒ Threshold çš„åˆ†å‰²çµæœè¦–è¦ºåŒ–

![Partition Comparison](partition_comparison.png)

**åœ–ä¾‹ï¼š** ğŸ”´ 64Ã—64 | ğŸ©µ 32Ã—32 | ğŸ”µ 16Ã—16 | ğŸŸ¢ 8Ã—8 | ğŸŸ¡ 4Ã—4

### ML-Only vs C Model vs Hybrid

![ML vs C Comparison](partition_ml_vs_c.png)

### Pareto Frontier Analysis

![Pareto Frontier](pareto_frontier.png)

| Threshold | Time (Î¼s) | Speedup | Accuracy | RDO Ops |
|-----------|-----------|---------|----------|---------|
| 0.50 | 23.92 | **4.64x** | 15.34% | 0 |
| 0.60 | 23.29 | **4.76x** | 15.34% | 0 |
| 0.70 | 45.75 | **2.43x** | 61.96% | 100 |
| 0.80 | 44.92 | **2.47x** | 61.96% | 100 |
| 0.90 | 95.50 | **1.16x** | 85.28% | 275 |
| 0.95 | 142.25 | 0.78x | 95.09% | 345 |
| 1.00 | 151.29 | 0.73x | 95.09% | 345 |
| 1.01 | 156.63 | 0.71x | **100.00%** | 461 |

### é—œéµç™¼ç¾

- **ML-Only Mode**: 4.76x åŠ é€Ÿï¼Œä½†æº–ç¢ºåº¦åƒ… 15%
- **Threshold = 1.01**: 100% æº–ç¢ºåº¦ï¼Œä½†æ¯” C Model é‚„æ…¢ï¼ˆæœ‰ ML é–‹éŠ·ï¼‰
- **æœ€ä½³å¹³è¡¡é»**: Threshold = 0.7~0.8ï¼Œç´„ **2.4x åŠ é€Ÿ** èˆ‡ **62% æº–ç¢ºåº¦**
- **é«˜æº–ç¢ºåº¦é¸é …**: Threshold = 0.9ï¼Œ**1.16x åŠ é€Ÿ** èˆ‡ **85% æº–ç¢ºåº¦**

### çµè«–

> "By tuning the ML confidence threshold, we achieved a **2.4x speedup** with **62% accuracy**, or **1.16x speedup** with **85% accuracy**. When threshold > 1.0, it falls back to pure RDO with 100% accuracy but slower due to ML overhead. This demonstrates the trade-off decisions made in real-world encoder optimization."

## ML æ¨¡å‹è¨­è¨ˆ

### ç‰¹å¾µ (Features)

| ç‰¹å¾µ | è¨ˆç®—æ–¹å¼ | æ„ç¾© |
|------|----------|------|
| `variance` | Î£(x - Î¼)Â² / n | å€å¡Šè¤‡é›œåº¦ |
| `grad_h` | Î£\|x[i,j] - x[i,j+1]\| / n | æ°´å¹³ç´‹ç† |
| `grad_v` | Î£\|x[i,j] - x[i+1,j]\| / n | å‚ç›´ç´‹ç† |

### è¼¸å‡º (å¸¶ Confidence)

```cpp
struct MLPrediction {
    bool should_split;    // é æ¸¬çµæœ
    double confidence;    // ä¿¡å¿ƒåº¦ (0.5 ~ 1.0)
};
```

### Decision Tree è½‰ C++

Python è¨“ç·´çš„æ¨¡å‹è‡ªå‹•è½‰è­¯ç‚ºç´” if-else çµæ§‹ï¼š
- é›¶é‹è¡Œæ™‚ä¾è³´
- Branch Prediction å‹å¥½
- å¯ç›´æ¥åµŒå…¥ Embedded ç³»çµ±

## æŠ€è¡“äº®é»

1. **çœŸå¯¦ RDO è¨ˆç®—**: ä½¿ç”¨ SSD + Rate Estimationï¼Œéæ¨¡æ“¬å»¶é²
2. **Confidence-based Fallback**: ML ä¸ç¢ºå®šæ™‚è‡ªå‹•å›é€€åˆ°ç²¾ç¢ºè¨ˆç®—
3. **Pareto Frontier åˆ†æ**: é‡åŒ– Speed vs Accuracy æ¬Šè¡¡
4. **Auto Code Generation**: Python â†’ C++ è‡ªå‹•è½‰è­¯

## å¾…æ”¹é€²

- [ ] å¢åŠ è¨“ç·´è³‡æ–™å¤šæ¨£æ€§ï¼ˆçœŸå¯¦åœ–ç‰‡/è¦–è¨Šå¹€ï¼‰
- [ ] å˜—è©¦å…¶ä»– ML æ¨¡å‹ï¼ˆRandom Forestã€XGBoostï¼‰
- [ ] å¯¦ä½œ HEVC/VVC ç·¨ç¢¼å™¨æ•´åˆ
- [ ] åŠ å…¥ PSNR/SSIM å“è³ªæŒ‡æ¨™

## ç’°å¢ƒéœ€æ±‚

- C++ Compiler (æ”¯æ´ C++11)
- Python 3.x
- pandas, scikit-learn
